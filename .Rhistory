library(car)
library(glmnet)
library(caret)
df <- read.csv("C:\Users\Juan Diego Pulido R\Desktop\Juan Diego\2024-1\Maestría\Análisis de datos\taller1.txt")
# Verificar la multicolinealidad
modelo <- lm(y ~ ., data = df)
# Verificar la multicolinealidad
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
df <- read.csv("C:\Users\Juan Diego Pulido R\Desktop\Juan Diego\2024-1\Maestría\Análisis de datos\taller1.txt")
# Cargar las librerías necesarias
install.packages(c("car", "glmnet", "caret"))
install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(car)
library(glmnet)
library(caret)
df <- read.csv("C:\Users\Juan Diego Pulido R\Desktop\Juan Diego\2024-1\Maestría\Análisis de datos\taller1.txt")
df <- read.csv("taller1.txt")
df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
# Verificar la multicolinealidad
modelo <- lm(y ~ ., data = df)
# Verificar la multicolinealidad
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
vif_df <- vif(modelo)
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
print(vif_df)
vif_df <- vif(modelo)
# Dividir los df
set.seed(1) # Establecer la semilla para reproducibilidad
indices <- sample(1:nrow(df), 1000)
df_entrenamiento <- df[indices, ]
df_prueba <- df[-indices, ]
# Determinar λr y λl
x <- model.matrix(y ~ ., data = df_entrenamiento)[,-1]
y <- df_entrenamiento$y
cv_ridge <- cv.glmnet(x, y, alpha = 0)
cv_lasso <- cv.glmnet(x, y, alpha = 1)
lambda_r <- cv_ridge$lambda.min
lambda_l <- cv_lasso$lambda.min
# Ajustar los modelos
modelo_ridge <- glmnet(x, y, alpha = 0, lambda = lambda_r)
modelo_lasso <- glmnet(x, y, alpha = 1, lambda = lambda_l)
#(5) Para los modelos ajustados en (4) determine el m´as apropiado para prop´ositos de predicci´on.
#Considere ´ unicamente el ECM en los 200 datos de prueba para su decisi´on.
# Seleccionar el mejor modelo
x_prueba <- model.matrix(y ~ ., data = df_prueba)[,-1]
y_prueba <- df_prueba$y
predicciones_ridge <- predict(modelo_ridge, s = lambda_r, newx = x_prueba)
predicciones_lasso <- predict(modelo_lasso, s = lambda_l, newx = x_prueba)
ECM_ridge <- mean((y_prueba - predicciones_ridge)^2)
ECM_lasso <- mean((y_prueba - predicciones_lasso)^2)
mejor_modelo <- ifelse(ECM_ridge < ECM_lasso, "Ridge", "Lasso")
# Ajustar el modelo seleccionado a todos los df
x_todos <- model.matrix(y ~ ., data = df)[,-1]
y_todos <- df$y
if (mejor_modelo == "Ridge") {
modelo_final <- glmnet(x_todos, y_todos, alpha = 0, lambda = lambda_r)
} else {
modelo_final <- glmnet(x_todos, y_todos, alpha = 1, lambda = lambda_l)
}
# Graficar las trazas de los coeficientes
plot(modelo_final, xvar = "lambda", label = TRUE)
# Resumen de los resultados
cat("El mejor modelo para predecir la efectividad del tratamiento anticancerígeno es", mejor_modelo, "con un ECM de", ifelse(mejor_modelo == "Ridge", ECM_ridge, ECM_lasso), "en los df de prueba.")
View(df)
library(car)
library(glmnet)
library(caret)
df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
#knitr::opts_chunk$set(echo = TRUE)
install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(caret)
df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
# Determinar λr y λl
x <- model.matrix(y ~ ., data = df_entrenamiento)[,-1]
y <- df_entrenamiento$y
cv_ridge <- cv.glmnet(x, y, alpha = 0)
cv_lasso <- cv.glmnet(x, y, alpha = 1)
lambda_r <- cv_ridge$lambda.min
lambda_l <- cv_lasso$lambda.min
print(lambda_r)
print(lambda_l)
set.seed(1) # Establecer la semilla para reproducibilidad
indices <- sample(1:nrow(df), 1000)
df_entrenamiento <- df[indices, ]
df_prueba <- df[-indices, ]
# Ajustar los modelos
modelo_ridge <- glmnet(x, y, alpha = 0, lambda = lambda_r)
modelo_lasso <- glmnet(x, y, alpha = 1, lambda = lambda_l)
x_prueba <- model.matrix(y ~ ., data = df_prueba)[,-1]
y_prueba <- df_prueba$y
predicciones_ridge <- predict(modelo_ridge, s = lambda_r, newx = x_prueba)
predicciones_lasso <- predict(modelo_lasso, s = lambda_l, newx = x_prueba)
ECM_ridge <- mean((y_prueba - predicciones_ridge)^2)
ECM_lasso <- mean((y_prueba - predicciones_lasso)^2)
mejor_modelo <- ifelse(ECM_ridge < ECM_lasso, "Ridge", "Lasso")
x_prueba <- model.matrix(y ~ ., data = df_prueba)[,-1]
y_prueba <- df_prueba$y
predicciones_ridge <- predict(modelo_ridge, s = lambda_r, newx = x_prueba)
predicciones_lasso <- predict(modelo_lasso, s = lambda_l, newx = x_prueba)
ECM_ridge <- mean((y_prueba - predicciones_ridge)^2)
ECM_lasso <- mean((y_prueba - predicciones_lasso)^2)
mejor_modelo <- ifelse(ECM_ridge < ECM_lasso, "Ridge", "Lasso")
knitr::opts_chunk$set(echo = TRUE)
install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(caret)
df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
library(MatrixModels)
knitr::opts_chunk$set(echo = TRUE)
install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(caret)
df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
