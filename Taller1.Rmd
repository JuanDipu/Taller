---
title: "Taller|"
output: html_document
date: "2024-03-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(caret)

df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
```

## Taller 1

(1) ¿Hay multicolinealidad en los datos? Explique sucintamente.

Verificar la multicolinealidad

```{r setup, include=FALSE}
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
print(vif_df)
```

El error en R al calcular el VIF (Variance Inflation Factor) indica que hay coeficientes aliased (coeficientes aliados) en el modelo de regresión. La multicolinealidad perfecta entre variables predictoras puede resultar en coeficientes aliased, lo que causa problemas en cálculos como el VIF.

(2) Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en dos partes

Dividir los df

```{r setup, include=FALSE}
set.seed(1) # Establecer la semilla para reproducibilidad
indices <- sample(1:nrow(df), 1000)
df_entrenamiento <- df[indices, ]
df_prueba <- df[-indices, ]
```

3) Usando los 1000 datos de entrenamiento, determine los valores de λr y λl de regesión ridge y lasso, respectivamente, que minimicen el error cuadr´atico medio (ECM) mediante validación externa. Utilice el m´etodo de validación externa que considere más apropiado.
