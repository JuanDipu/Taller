---
title: "Taller|"
output: html_document
date: "2024-03-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

install.packages(c("car", "glmnet", "caret"))
library(car)
library(glmnet)
library(caret)

df <- read.csv("C:/Users/Juan Diego Pulido R/Desktop/Juan Diego/2024-1/Maestría/Análisis de datos/taller1.txt")
```

## Taller 1

(1) ¿Hay multicolinealidad en los datos? Explique sucintamente.

Verificar la multicolinealidad

```{r setup, include=FALSE}
modelo <- lm(y ~ ., data = df)
vif_df <- vif(modelo)
print(vif_df)
```

El error en R al calcular el VIF (Variance Inflation Factor) indica que hay coeficientes aliased (coeficientes aliados) en el modelo de regresión. La multicolinealidad perfecta entre variables predictoras puede resultar en coeficientes aliased, lo que causa problemas en cálculos como el VIF.

(2) Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en dos partes

Dividir los df

```{r setup, include=FALSE}
set.seed(1) # Establecer la semilla para reproducibilidad
indices <- sample(1:nrow(df), 1000)
df_entrenamiento <- df[indices, ]
df_prueba <- df[-indices, ]
```

3)  Usando los 1000 datos de entrenamiento, determine los valores de λr y λl de regesión ridge y lasso, respectivamente, que minimicen el error cuadr´atico medio (ECM) mediante validación externa. Utilice el método de validación externa que considere más apropiado.

```{r setup, include=FALSE}
# Determinar λr y λl
x <- model.matrix(y ~ ., data = df_entrenamiento)[,-1]
y <- df_entrenamiento$y
cv_ridge <- cv.glmnet(x, y, alpha = 0)
cv_lasso <- cv.glmnet(x, y, alpha = 1)
lambda_r <- cv_ridge$lambda.min
lambda_l <- cv_lasso$lambda.min
print(lambda_r)
print(lambda_l)
```

(4) Ajuste la regresión ridge y lasso con los valores estimados de λr y λl obtenidos en (3) usando los 1000 datos de entrenamiento.

```{r setup, include=FALSE}
# Ajustar los modelos
modelo_ridge <- glmnet(x, y, alpha = 0, lambda = lambda_r)
modelo_lasso <- glmnet(x, y, alpha = 1, lambda = lambda_l)
```

5) Para los modelos ajustados en (4) determine el más apropiado para propósitos de predicción. Considere unicamente el ECM en los 200 datos de prueba para su decisión. Seleccionar el mejor modelo
```{r setup, include=FALSE}
x_prueba <- model.matrix(y ~ ., data = df_prueba)[,-1]
y_prueba <- df_prueba$y
predicciones_ridge <- predict(modelo_ridge, s = lambda_r, newx = x_prueba)
predicciones_lasso <- predict(modelo_lasso, s = lambda_l, newx = x_prueba)
ECM_ridge <- mean((y_prueba - predicciones_ridge)^2)
ECM_lasso <- mean((y_prueba - predicciones_lasso)^2)
mejor_modelo <- ifelse(ECM_ridge < ECM_lasso, "Ridge", "Lasso")
```
